#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Tue Nov 13 00:05:12 2018

@author: atatarian
"""

#generate a script that evaluates which model quadratic (a + bx + cw^2) 
#or linear (a +bx) is more appropriate for the data in data.txt

import numpy
import pandas
from scipy.optimize import minimize
from scipy.stats import norm
from plotnine import *

data=pandas.read_csv("data.txt",sep=",",header=0)

a=ggplot(data,aes(x="x",y="y"))

print a+geom_point()+coord_cartesian()

### Custom likelihood function - linear
def nllike(p,obs):
    B0=p[0] #y-intercept
    B1=p[1] #slope
    sigma=p[2]
    
    expected=B0+B1*obs.x
    nll=-1*norm(expected,sigma).logpdf(obs.y).sum()
    return nll

### estimate parameters by minimizing the negative log likelihood
initialGuess=numpy.array([1,1,1])
fit=minimize(nllike,initialGuess,method="Nelder-Mead",options={'disp': True},args=data)

# fit is a variable that contains an OptimizeResult object
# attribute 'x' is a list of the most likely parameter values
print(fit.x)

### Custom likelihood function -quadratic
def nllike2(p,obs):
    B0=p[0] #y-intercept
    B1=p[1] #slope
    B2=p[2]
    sigma=p[3]
    
    expected=B0+B1*obs.x+B2*obs.x*obs.x
    nll=-1*norm(expected,sigma).logpdf(obs.y).sum()
    return nll

### estimate parameters by minimizing the negative log likelihood
initialGuess=numpy.array([1,1,1,1])
fit2=minimize(nllike2,initialGuess,method="Nelder-Mead",options={'disp': True},args=data)

# fit is a variable that contains an OptimizeResult object
# attribute 'x' is a list of the most likely parameter values
print(fit2.x)

#now that we have the likelihoods of each test, conduct t test (likelihood ratio test)

#need a likelihood ratio test:
from scipy import stats
teststat=2*(fit.fun-fit2.fun)
df=len(fit2.x)-len(fit.x)


print (1-stats.chi2.cdf(teststat,df))

#The strong, positive correlation of 0.899 between the two models shows that
#both are useful, so it is best to use the linear model becasue it is simpler.

